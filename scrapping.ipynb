{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URL = \"https://papers.nips.cc/\"\n",
    "YEARS = range(2024, 2019, -1)\n",
    "DOWNLOAD_DIR = r\"C:\\\\Users\\\\Qadri Laptop\\\\NeurIPS_Papers\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "def get_paper_links(year):\n",
    "    response = requests.get(f\"{BASE_URL}paper_files/paper/{year}\")\n",
    "    if response.status_code != 200:\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return [BASE_URL.rstrip(\"/\") + link.get(\"href\") for link in soup.find_all(\"a\")\n",
    "            if link.get(\"href\", \"\").startswith(\"/paper_files/paper/\") and link.get(\"href\").endswith(\".html\")]\n",
    "\n",
    "def download_paper(paper_url, year):\n",
    "    response = requests.get(paper_url)\n",
    "    if response.status_code != 200:\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    pdf_link = next((BASE_URL.rstrip(\"/\") + link.get(\"href\")\n",
    "                    for link in soup.find_all(\"a\") if \"Paper\" in link.text), None)\n",
    "    \n",
    "    if not pdf_link or os.path.exists(file_path := os.path.join(DOWNLOAD_DIR, str(year), pdf_link.split(\"/\")[-1])):\n",
    "        return\n",
    "\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        for chunk in requests.get(pdf_link, stream=True).iter_content(1024):\n",
    "            file.write(chunk)\n",
    "    print(f\"Downloaded: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for year in YEARS:\n",
    "        for paper_url in get_paper_links(year):\n",
    "            download_paper(paper_url, year)\n",
    "    print(\"Scraping completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
