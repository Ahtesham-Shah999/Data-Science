{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URL = \"https://papers.nips.cc\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "YEAR = 2024\n",
    "MAX_PAPERS = 370\n",
    "\n",
    "def fetch_paper_links(year):\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/paper_files/paper/{year}\", headers=HEADERS, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        return [a['href'] for a in soup.find_all('a', href=True) if \"/paper/\" in a['href']][:MAX_PAPERS]\n",
    "    except requests.RequestException:\n",
    "        return []\n",
    "\n",
    "def extract_paper_details(paper_link, serial_no):\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}{paper_link}\", headers=HEADERS, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        title = (soup.find('h4').text.strip() if soup.find('h4') else \"No Title\")\n",
    "        authors = (soup.find('h4', string=\"Authors\").find_next('p').find('i').text.strip()\n",
    "                   if soup.find('h4', string=\"Authors\") else \"No Authors\")\n",
    "        abstract = (soup.find('h4', string=\"Abstract\").find_next('p').text.strip()\n",
    "                    if soup.find('h4', string=\"Abstract\") else \"No Abstract\")\n",
    "        pdf_link = (BASE_URL + soup.find('a', string=\"Paper\")['href']\n",
    "                    if soup.find('a', string=\"Paper\") else \"No PDF\")\n",
    "        return [serial_no, title, authors, abstract, pdf_link]\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    paper_links = fetch_paper_links(YEAR)\n",
    "    data = [extract_paper_details(link, i) for i, link in enumerate(paper_links, 1) if extract_paper_details(link, i)]\n",
    "    pd.DataFrame(data, columns=[\"Serial No\", \"Title\", \"Authors\", \"Abstract\", \"PDF Link\"]).to_csv(f\"neurips_papers_{YEAR}.csv\", index=False)\n",
    "    print(f\"âœ… CSV file 'neurips_papers_{YEAR}.csv' created successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
